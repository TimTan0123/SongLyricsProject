"""
This module contains code to do the following:
    1. Text tokenization
    2. Text normalization
    3. n-grams
    4. POS Tagging
    5. language detection
"""
import nltk

# Tokenization
def sl_tokenizer():
    # 1. sentence tokenization
    # 2. word level tokenization
    pass


# Normalization
def sl_normalization():
    # 1. remove punctuations
    # 2. lower-case
    # 3. stop-word removal (optional)
    # 4. lemmatization
    # 5. stemming
    # 6. text expansion/abbreviation expansion (don't ==> do not)
    # 7. synonyms
    # 8. convert numbers to words
    pass

def sl_ngrams(n_gram = 2):
    # return the n-grams
    pass

def sl_tags(text):
    # return pos tags for each word
    pass

def sl_language(text):
    # detect language
    pass